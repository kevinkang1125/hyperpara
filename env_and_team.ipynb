{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77338767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ijcai2022nmmo import CompetitionConfig, scripted, TeamBasedEnv, Team\n",
    "import nmmo\n",
    "import numpy as np\n",
    "import copy\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from gym import spaces \n",
    "from nmmo.io import action\n",
    "\n",
    "\n",
    "class MyTrainEnv(gym.Env):\n",
    "    def __init__(self,env_config:dict):\n",
    "        self.config = CompetitionConfig()\n",
    "        self.team_env = TeamBasedEnv(self.config)\n",
    "        self.env_config = env_config\n",
    "        #observation_space = [spaces.MultiDiscrete(2*np.ones((129,129),dtype=np.int32))]*8\n",
    "        self.observation_space = spaces.Tuple(( spaces.Box(low=-np.infty,high=np.infty,shape=(129,129,40),dtype=np.float32),\n",
    "                                               spaces.Box(low=-np.infty,high=np.infty,shape=(88,),dtype=np.float32) \n",
    "                                             ))\n",
    "        self.action_space = spaces.Box(low=-np.infty,high=np.infty,shape=(80,),dtype=np.float32)\n",
    "        self.t = 0\n",
    "        \n",
    "    def reset(self):\n",
    "        self.obs_by_team = self.team_env.reset()\n",
    "        self.n_tick = 0 \n",
    "        ##### establish the teams:\n",
    "        self.teams = []\n",
    "        self.teams += [MyAwesomeTeam(\"MyTeam\",self.config)]\n",
    "        team_config = self.env_config[\"teams\"]\n",
    "        for key, team_num in team_config.items():\n",
    "            if team_num>0:\n",
    "                designed_team = getattr(scripted,key)\n",
    "                self.teams += [designed_team(key+f\"-{i}\",self.config) for i in range(team_num)] \n",
    "        ############################\n",
    "        \n",
    "        for team in self.teams:\n",
    "            team.reset()\n",
    "        \n",
    "        # myteam population id = 0\n",
    "        obs_to_myteam = obs_by_team[0]\n",
    "        \n",
    "        new_obs = self.teams[0].update_map(obs_to_myteam)\n",
    "        return new_obs\n",
    "        \n",
    "    def step(self,action):\n",
    "        actions = {}\n",
    "        ####### convert the output of the policy into the true action\n",
    "        new_my_action = sself.teams[0].act(action)\n",
    "        \n",
    "        \n",
    "        actions[0]=new_my_actions\n",
    "        ############\n",
    "        \n",
    "        ####### obtain the actions of other teams\n",
    "        for team_index in range(1,16):\n",
    "            other_actions = self.teams[team_index].act(self.obs_by_team[team_index])\n",
    "            actions[team_index] = other_actions\n",
    "        self.obs_by_team = self.team_env.step(actions)\n",
    "        obs_to_myteam = self.obs_by_team[0]\n",
    "        \n",
    "        new_my_obs = self.teams[0].update_map(obs_to_myteam)\n",
    "        \n",
    "        self.n_tick += 1 \n",
    "        \n",
    "        \n",
    "        ######## reward\n",
    "        def cal_rwd(init, seg1, seg2, seg3, prev, curr):\n",
    "            k = [4 / (seg1 - init), 6 / (seg2 - seg1), 11 / (seg3 - seg2)]\n",
    "            seg = [seg1, seg2, seg3]\n",
    "\n",
    "            rwd = 0\n",
    "            for i in range(3):\n",
    "                if prev < seg[i]:\n",
    "                    incre = min(curr - prev, seg[i] - prev)\n",
    "                    rwd += k[i] * incre\n",
    "                    prev += incre\n",
    "                    if prev == curr:\n",
    "                        return rwd\n",
    "            \n",
    "            return rwd\n",
    "        \n",
    "        def find_exploration(exploration_map):\n",
    "            if exploration_map.sum() == 0:\n",
    "                return 0\n",
    "            i_l, j_l, i_r, j_r = 0, 0, 0, 0\n",
    "            for i in range(exploration_map.shape[0]):\n",
    "                for j in range(exploration_map.shape[1]):\n",
    "                    if exploration_map[i][j]:\n",
    "                        i_l = i\n",
    "                        j_l = j\n",
    "                        break\n",
    "            for i in range(exploration_map.shape[0] - 1, -1, -1):\n",
    "                for j in range(exploration_map.shape[1] - 1, -1, -1):\n",
    "                    if exploration_map[i][j]:\n",
    "                        i_r = i\n",
    "                        j_r = j\n",
    "                        break\n",
    "            \n",
    "            return max(np.abs(i_r - i_l), np.abs(j_r - j_l))\n",
    "            \n",
    "\n",
    "        reward = 0\n",
    "        done=False\n",
    "        info = {}\n",
    "        \n",
    "        ### hunting and fishing 21\n",
    "        rwd_hunting = cal_rwd(10, 20, 35, 50, self.last_global_information[\"hunting_level\"], self.global_information[\"hunting_level\"])\n",
    "        rwd_fishing = cal_rwd(10, 20, 35, 50, self.last_global_information[\"fishing_level\"], self.global_information[\"fishing_level\"])\n",
    "        rwd_resources = (rwd_hunting + rwd_fishing) / 2\n",
    "\n",
    "        ### defeat players 21\n",
    "        rwd_kill = cal_rwd(0, 1, 3, 6, self.last_global_information[\"kill_opponent_num\"], self.global_information[\"kill_opponent_num\"])\n",
    "\n",
    "        ### exploration 21\n",
    "        for idx in range(8):\n",
    "            exploration_map = self.global_map[\"agents\"][\"layers\"][:,:,idx*2+1]\n",
    "            self.global_information[\"exploration\"] = max(find_exploration(exploration_map), self.global_information[\"exploration\"])\n",
    "        rwd_exploration = cal_rwd(0, 32, 64, 127, self.last_global_information[\"exploration\"], self.global_information[\"exploration\"])\n",
    "        self.last_global_information[\"exploration\"] = self.global_information[\"exploration\"]\n",
    "        \n",
    "        ### food and water\n",
    "        rwd_food_and_water = 0\n",
    "        for idx in range(8):\n",
    "            food = self.global_map['agents']['vectors'][idx*11+2]\n",
    "            water = self.global_map['agents']['vectors'][idx*11+3]\n",
    "            if food < 0.3 * self.global_information[\"hunting_level\"]:\n",
    "                rwd_food_and_water += -0.02\n",
    "            if water < 0.3 * self.global_information[\"fishing_level\"]:\n",
    "                rwd_food_and_water += -0.02\n",
    "        \n",
    "        ### equipment\n",
    "        rwd_equip = 0\n",
    "        if self.global_information['kill_npc_level'] > self.last_global_information['kill_npc_level']:\n",
    "            rwd_equip = cal_rwd(0, 1, 10, 20, self.last_global_information[\"kill_npc_level\"], self.global_information[\"kill_npc_level\"])\n",
    "        \n",
    "        ### level\n",
    "        alive = False\n",
    "        rwd_level = 0\n",
    "        for idx in range(8):\n",
    "            level = self.global_map['agents']['vectors'][idx*11+0]\n",
    "            if level > 0:\n",
    "                alive = True\n",
    "            self.global_information['level'] = max(self.global_information['level'], level)\n",
    "        rwd_level += (self.global_information['level'] - self.last_global_information['level']) * 21 / 80\n",
    "        self.last_global_information['level'] = self.global_information['level']\n",
    "\n",
    "        ### alive\n",
    "        rwd_alive = 0\n",
    "        if alive:\n",
    "            rwd_alive += 0.02\n",
    "        \n",
    "        reward = rwd_resources + rwd_kill + rwd_exploration + rwd_food_and_water + rwd_equip + rwd_level + rwd_alive\n",
    "            \n",
    "        ######## done\n",
    "        done = False\n",
    "        self.t += 1\n",
    "        if self.t >= 1024 or not alive:\n",
    "            done = True\n",
    "        \n",
    "        return new_my_obs, reward, done, info\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95285729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################\n",
    "## Myteam\n",
    "class MyAwesomeTeam(Team):\n",
    "    def reset(self):\n",
    "        # reset some states\n",
    "        self.global_map = {}\n",
    "        self.n_tick = 0 \n",
    "        self.LOCAL_BIAS = 16\n",
    "        self.global_information={ \"hunting_level\":10, \n",
    "                                  \"fishing_level\":10,\n",
    "                                  \"kill_npc_level\":0,\n",
    "                                  \"kill_npc_num\":0,\n",
    "                                  \"kill_opponent_num\":0,\n",
    "                                  \"exploration\":0,\n",
    "                                  \"level\": 1}\n",
    "        self.last_global_information={ \"hunting_level\":10, \n",
    "                                       \"fishing_level\":10,\n",
    "                                       \"kill_npc_level\":0,\n",
    "                                       \"kill_npc_num\":0,\n",
    "                                       \"kill_opponent_num\":0,\n",
    "                                       \"exploration\":0,\n",
    "                                       \"level\": 1}\n",
    "        self.last_action_informations= [ [0,0] for i in range(8) ]  # id-level\n",
    "    \n",
    "    def obs_normalization(self,agent_layers,agent_vectors,opponents,npcs,terrain):\n",
    "        MAX_LEVEL = 80\n",
    "        MAX_HEALTH = MAX_LEVEL\n",
    "        MAX_FOOD = 80 \n",
    "        MAX_WATER = 80\n",
    "        MAX_DAMAGE = 1000\n",
    "        MAX_HUNTING_LEVEL = 75 \n",
    "        MAX_FISHING_LEVEL = 75 \n",
    "        MAX_KILL_NUM = 20\n",
    "        \n",
    "        # normalization for the agents\n",
    "        for agent_index in range(8):\n",
    "            # level\n",
    "            agent_vectors[agent_index*11+0] /= MAX_LEVEL\n",
    "            # health\n",
    "            agent_vectors[agent_index*11+1] /= MAX_HEALTH\n",
    "            # food\n",
    "            agent_vectors[agent_index*11+2] /= MAX_FOOD\n",
    "            # water \n",
    "            agent_vectors[agent_index*11+3] /= MAX_WATER\n",
    "            # DAMAGE \n",
    "            agent_vectors[agent_index*11+4] /= MAX_DAMAGE\n",
    "            # HUNTING_LEVEL\n",
    "            agent_vectors[agent_index*11+6] /= MAX_HUNTING_LEVEL\n",
    "            # FISHING LEVEL \n",
    "            agent_vectors[agent_index*11+7] /= MAX_FISHING_LEVEL\n",
    "            # KILL_NPC_LEVEL\n",
    "            agent_vectors[agent_index*11+8] /= MAX_LEVEL\n",
    "            # kill_npc_num\n",
    "            agent_vectors[agent_index*11+9] /= MAX_KILL_NUM\n",
    "            # KILL_OPPONENT_NUM\n",
    "            agent_vectors[agent_index*11+10] /= MAX_KILL_NUM\n",
    "        \n",
    "        MAX_DIS_NUM = 5\n",
    "        # normalization for the opponents AND NPCS \n",
    "        # distribution \n",
    "        opponents[:,:,0] /= MAX_DIS_NUM \n",
    "        npcs[:,:,0] /= MAX_DIS_NUM\n",
    "        # level \n",
    "        opponents[:,:,1] /= MAX_LEVEL\n",
    "        npcs[:,:,1] /= MAX_LEVEL\n",
    "        # damage\n",
    "        opponents[:,:,2] /= MAX_DAMAGE\n",
    "        npcs[:,:,2] /= MAX_DAMAGE\n",
    "        # food \n",
    "        opponents[:,:,3] /= MAX_FOOD\n",
    "        npcs[:,:,3] /= MAX_FOOD\n",
    "        # water \n",
    "        opponents[:,:,4] /= MAX_WATER\n",
    "        npcs[:,:,4] /= MAX_WATER\n",
    "        # health\n",
    "        opponents[:,:,5] /= MAX_HEALTH\n",
    "        npcs[:,:,5] /= MAX_HEALTH\n",
    "        \n",
    "        ##### clip between [0,1]\n",
    "        agent_layers = np.clip(agent_layers,0,1)\n",
    "        opponents = np.clip(opponents,0,1)\n",
    "        npcs = np.clip(npcs,0,1)\n",
    "        terrain = np.clip(terrain,0,1)\n",
    "        agent_vectors = np.clip(agent_vectors,0,1)\n",
    "        \n",
    "        # concatenate\n",
    "        obs_layers = np.concatenate( (agent_layers,opponents,npcs,terrain),axis=-1 )\n",
    "        \n",
    "        return ( obs_layers, agent_vectors )\n",
    "            \n",
    "    \n",
    "    def update_map(self,observations:dict[int,dict]):\n",
    "        ############# agent layer information\n",
    "        agent_visible = np.zeros([129,129])\n",
    "        agent_info = np.zeros([129,129,16])\n",
    "        agents_dis = np.zeros([129,129])\n",
    "        ############# agent vector information\n",
    "        agent_vectors = np.zeros([88])\n",
    "        ############# opponent layer information\n",
    "        opponents=np.zeros([129,129,7])\n",
    "        ############# npc layer infromation\n",
    "        npcs=np.zeros([129,129,7])\n",
    "        ############# record the attack objects \n",
    "        self.attack_objs = []\n",
    "        for k in self.global_information:\n",
    "            self.last_global_information[k] = self.global_information[k]\n",
    "        for agent_index in range(8):\n",
    "            attack_obj = []\n",
    "            if observations.get(agent_index)!=None:\n",
    "                ######## obttain the obs from the env\n",
    "                obs_en = observations[agent_index]['Entity']['Continuous']\n",
    "                ######## team pop \n",
    "                team_id = int( obs_en[0][4] )\n",
    "                ########  agent row | column index \n",
    "                agent_row_index = int( obs_en[0][5]- self.LOCAL_BIAS )\n",
    "                agent_column_index = int( obs_en[0][6] - self.LOCAL_BIAS ) \n",
    "                ######## opponents, npcs location\n",
    "                opponents_loc = []\n",
    "                npcs_loc = []\n",
    "                \n",
    "                ######## information for npcs killing and opponents killing\n",
    "                last_object_list = []\n",
    "                \n",
    "                ######## \n",
    "                for index in range(100):\n",
    "                    info = int(obs_en[index][0])\n",
    "                    if info==0:\n",
    "                        break\n",
    "                    entity_id = int(obs_en[index][1]) # entity_id\n",
    "                    level = int( obs_en[index][3] )   # agent level \n",
    "                    pop = int( obs_en[index][4])      # agent pop \n",
    "                    row_index = int( obs_en[index][5]- self.LOCAL_BIAS )  # row index \n",
    "                    column_index = int( obs_en[index][6] - self.LOCAL_BIAS ) # column index \n",
    "                    damage = int( obs_en[index][7] )  # damage received \n",
    "                    timealive = int( obs_en[index][8] ) # timealive\n",
    "                    food = int( obs_en[index][9] )  # food \n",
    "                    water = int( obs_en[index][10] ) # water\n",
    "                    health = int( obs_en[index][11] ) # health \n",
    "                    frozen = int( obs_en[index][12] ) # frozen \n",
    "\n",
    "                    if index==0:\n",
    "                        # 表示是该team的agent\n",
    "                        ### update layers \n",
    "                        ######### 更新 agent_visible\n",
    "                        agent_visible[int(max(row_index-7,0)):int(min(row_index+8,129)),\n",
    "                                      int(max(column_index-7,0)):int(min(column_index+8,129))] = 1\n",
    "                        ######### update agent info\n",
    "                        ################################   alive\n",
    "                        agent_info[row_index][column_index][agent_index*2+0]=1\n",
    "                        ################################   exploration\n",
    "                        if self.global_map=={}: # first step\n",
    "                            agent_info[:,:,agent_index*2+1]=agent_visible\n",
    "                        else:\n",
    "                            agent_info[:,:,agent_index*2+1] = self.global_map[\"agents\"][\"layers\"][:,:,agent_index*2+1]\n",
    "                            agent_info[int(max(row_index-7,0)):int(min(row_index+8,129)),\n",
    "                                      int(max(column_index-7,0)):int(min(column_index+8,129)),\n",
    "                                      agent_index*2+1] = 1\n",
    "                            \n",
    "                        ######### agent 更新 agent dis\n",
    "                        agents_dis[row_index][column_index]=1 # locations \n",
    "                        \n",
    "                        ### update agent vectors \n",
    "                        ######### agent 更新 agent level\n",
    "                        agent_vectors[agent_index*11+0]=level\n",
    "                        ######### agent 更新 agent health\n",
    "                        agent_vectors[agent_index*11+1]=health\n",
    "                        ######### agent 更新 agent food\n",
    "                        agent_vectors[agent_index*11+2]=food                        \n",
    "                        ######### agent 更新 agent water\n",
    "                        agent_vectors[agent_index*11+3]=water\n",
    "                        ######### agent 更新 agent damage\n",
    "                        agent_vectors[agent_index*11+4]=damage                        \n",
    "                        ######### agent 更新 agent frozen\n",
    "                        agent_vectors[agent_index*11+5]=frozen  \n",
    "                        \n",
    "                        ######### agent 更新 hunting level\n",
    "                        self.global_information[\"hunting_level\"] = max(food,self.global_information[\"hunting_level\"])\n",
    "                        agent_vectors[agent_index*11+6] = self.global_information[\"hunting_level\"]\n",
    "                        \n",
    "                        ######### agent 更新 fishing level\n",
    "                        self.global_information[\"fishing_level\"] = max(water,self.global_information[\"fishing_level\"])\n",
    "                        agent_vectors[agent_index*11+7] = self.global_information[\"fishing_level\"]\n",
    "\n",
    "                        ######### agent 更新 timealive\n",
    "                        self.n_tick = timealive\n",
    "\n",
    "                        #############################################################\n",
    "                    else:\n",
    "                        if pop>0 and pop!=team_id: # opponent\n",
    "                            ######## opponent distribution\n",
    "                            opponents[row_index][column_index][0]+=1\n",
    "                            ######## level\n",
    "                            opponents[row_index][column_index][1]+=level\n",
    "                            ######## damage\n",
    "                            opponents[row_index][column_index][2]+=damage\n",
    "                            ######## food\n",
    "                            opponents[row_index][column_index][3]+=food\n",
    "                            ######## water\n",
    "                            opponents[row_index][column_index][4]+=water                                \n",
    "                             ######## health\n",
    "                            opponents[row_index][column_index][5]+=health\n",
    "                            ######## frozen\n",
    "                            opponents[row_index][column_index][6]+=frozen\n",
    "\n",
    "                            ######## killing opponents\n",
    "                            if self.last_action_informations[agent_index][0]>0:\n",
    "                                last_object_list.append(entity_id)\n",
    "                            \n",
    "                            if [row_index,column_index] not in opponents_loc:\n",
    "                                opponents_loc.append( [row_index,column_index] )\n",
    "                            attack_obj.append([entity_id,\n",
    "                                               abs(row_index-agent_row_index),\n",
    "                                               abs(column_index-agent_column_index),\n",
    "                                              level,\n",
    "                                              damage,\n",
    "                                              food,\n",
    "                                              water,\n",
    "                                              health,\n",
    "                                              frozen])\n",
    "                        elif pop<0: # npcs \n",
    "                            ######## npc distribution\n",
    "                            npcs[row_index][column_index][0]+=1\n",
    "                            ######## level\n",
    "                            npcs[row_index][column_index][1]+=level\n",
    "                            ######## damage\n",
    "                            npcs[row_index][column_index][2]+=damage\n",
    "                            ######## food\n",
    "                            npcs[row_index][column_index][3]+=food\n",
    "                            ######## water\n",
    "                            npcs[row_index][column_index][4]+=water                                \n",
    "                            ######## health\n",
    "                            npcs[row_index][column_index][5]+=health\n",
    "                            ######## frozen\n",
    "                            npcs[row_index][column_index][6]+=frozen      \n",
    "                            \n",
    "                            ############ killing npcs \n",
    "                            if self.last_action_informations[agent_index][0]<0:\n",
    "                                last_object_list.append(entity_id)\n",
    "                                \n",
    "                            if [row_index,column_index] not in npcs_loc:\n",
    "                                npcs_loc.append([row_index,column_index])\n",
    "                                \n",
    "                            attack_obj.append([entity_id,\n",
    "                                               abs(row_index-agent_row_index),\n",
    "                                               abs(column_index-agent_column_index),\n",
    "                                              level,\n",
    "                                              damage,\n",
    "                                              food,\n",
    "                                              water,\n",
    "                                              health,\n",
    "                                              frozen])\n",
    "                \n",
    "                for loc in opponents_loc:\n",
    "                    for i in range(1,7):\n",
    "                        opponents[loc[0]][loc[1]][i] = int( opponents[loc[0]][loc[1]][i]/opponents[loc[0]][loc[1]][0])\n",
    "                for loc in npcs_loc:\n",
    "                    for i in range(1,7):\n",
    "                        npcs[loc[0]][loc[1]][i] = int(npcs[loc[0]][loc[1]][i]/npcs[loc[0]][loc[1]][0])\n",
    "            ### update the killing information:\n",
    "            if self.last_action_informations[agent_index][0]>0 and \\\n",
    "               self.last_action_informations[agent_index][0] not in last_object_list :\n",
    "                self.global_information[\"kill_opponent_num\"]+=1\n",
    "            elif self.last_action_informations[agent_index][0]<0 and \\\n",
    "               self.last_action_informations[agent_index][0] not in last_object_list :\n",
    "                self.global_information[\"kill_npc_num\"]+=1\n",
    "                self.global_information[\"kill_npc_level\"] = max(self.global_information[\"kill_npc_level\"],\n",
    "                                                               self.last_action_informations[agent_index][1])\n",
    "            \n",
    "            ####### update the killing information:\n",
    "            ### kill_npc level \n",
    "            agent_vectors[agent_index*11+8] = self.global_information[\"kill_npc_level\"]\n",
    "            ### kill_npc_num\n",
    "            agent_vectors[agent_index*11+9] = self.global_information[\"kill_npc_num\"]\n",
    "            ### kill_opponent_num \n",
    "            agent_vectors[agent_index*11+10] = self.global_information[\"kill_opponent_num\"]\n",
    "            \n",
    "            self.attack_objs.append(np.array(attack_obj,dtype=np.float32))\n",
    "        ##################### terrain update\n",
    "        if self.global_map=={}: # first step\n",
    "            terrain = np.zeros([129,129,8])  \n",
    "            for agent_index in range(8):\n",
    "                if observations.get(agent_index)!=None:\n",
    "                    obs_til = observations[agent_index]['Tile']['Continuous']\n",
    "                    for index in range(225):\n",
    "                        til_type = int( obs_til[index][1] )\n",
    "                        til_row = int( obs_til[index][2] -self.LOCAL_BIAS )\n",
    "                        til_column = int( obs_til[index][3] -self.LOCAL_BIAS ) \n",
    "                        if til_row<0 or til_row > 128 or til_column<0 or til_column>128:\n",
    "                            continue \n",
    "\n",
    "                        terrain[til_row][til_column][0]= 1\n",
    "                        terrain[til_row][til_column][til_type]=1\n",
    "        else:\n",
    "            terrain = self.global_map['terrain']\n",
    "            for i in range(129):\n",
    "                for j in range(129):\n",
    "                    if terrain[i][j][3]==1:\n",
    "                        terrain[i][j][6]=1\n",
    "                    if terrain[i][j][4]==1:\n",
    "                        terrain[i][j][7]=1       \n",
    "            for agent_index in range(8):     \n",
    "                if observations.get(agent_index)!=None:\n",
    "                    obs_til = observations[agent_index]['Tile']['Continuous']\n",
    "                    for index in range(225):\n",
    "                        til_type = int( obs_til[index][1] )\n",
    "                        til_row = int( obs_til[index][2] -self.LOCAL_BIAS )\n",
    "                        til_column = int( obs_til[index][3] -self.LOCAL_BIAS ) \n",
    "                        if til_row<0 or til_row > 128 or til_column<0 or til_column>128:\n",
    "                            continue \n",
    "\n",
    "                        terrain[til_row][til_column][0]= 1\n",
    "                        terrain[til_row][til_column][til_type]=1\n",
    "\n",
    "                        if til_type==3 or til_type==4:\n",
    "                            terrain[til_row][tile_column][6]=0\n",
    "                            terrain[til_row][tile_column][6]=0\n",
    "                                \n",
    "        ######## concatenate                        \n",
    "        self.global_map['terrain']=terrain\n",
    "        self.global_map['oppos']=opponents\n",
    "        self.global_map['npcs']=npcs\n",
    "        \n",
    "        agent_visible_expanded = np.expand_dims(agent_visible,axis=-1)\n",
    "        agents_dis_expanded = np.expand_dims(agents_dis,axis=-1)\n",
    "        agent_layers = np.concatenate( (agent_info,agent_visible_expanded,agents_dis_expanded),axis=-1 )\n",
    "        self.global_map['agents']={\"layers\":agent_layers, \"vectors\":agent_vectors}\n",
    "\n",
    "        obs = self.obs_normalization(copy.deepcopy(agent_layers),\n",
    "                                     copy.deepcopy(agent_vectors),\n",
    "                                     copy.deepcopy(opponents),\n",
    "                                     copy.deepcopy(npcs),\n",
    "                                     copy.deepcopy(terrain))\n",
    "        \n",
    "        return obs\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def show_map(self,characters,agent_attris,attris,agent_index=0,terrain_option=False,ter_attris=[0,1,2,3,4,5,6,7]):\n",
    "        \"\"\"\n",
    "        characters :  [\"agents\",\"oppos\",\"npcs\"]\n",
    "        attris = [0,1,2,3,4,5,6]\n",
    "        ter_attris = [0,1,2,3,4,5,6,7]\n",
    "        \"\"\"\n",
    "        \n",
    "        CHARAC = ['distribution','level','damage','food','water','health','is_frozen']\n",
    "        AGENTS = [\"location\",\"exploration\",'visible','agents distribution']\n",
    "        TERRAIN = [\"exploration\",\"water\",\"grass\",\"scrub(latest)\",\"forest(latest)\",\n",
    "                   \"stone\",\"scrub(previous)\",\"forest(previous)\"]\n",
    "        i = 0\n",
    "        for character in characters:\n",
    "            if character == \"agents\":\n",
    "                for attri in agent_attris:\n",
    "                    plt.figure(i)\n",
    "                    i+=1\n",
    "                    ######## show agents \n",
    "                    plt.imshow(self.global_map[character][\"layers\"][:,:,agent_index*2+attri],cmap=plt.cm.cool)\n",
    "                    plt.colorbar()\n",
    "                    plt.title(character+\" \"+AGENTS[attri])\n",
    "                    plt.show()\n",
    "                    \n",
    "                plt.figure(i)\n",
    "                i+=1\n",
    "                plt.imshow(self.global_map[character][\"layers\"][:,:,-2],cmap=plt.cm.cool)\n",
    "                plt.colorbar()\n",
    "                plt.title(AGENTS[-2])\n",
    "                \n",
    "                plt.figure(i)\n",
    "                i+=1\n",
    "                plt.imshow(self.global_map[character][\"layers\"][:,:,-1],cmap=plt.cm.cool)\n",
    "                plt.colorbar()\n",
    "                plt.title(AGENTS[-1])                \n",
    "            else:\n",
    "                for attri in attris:\n",
    "                    plt.figure(i)\n",
    "                    i+=1\n",
    "                    plt.imshow(self.global_map[character][:,:,agent_index*8+attri],cmap=plt.cm.cool)\n",
    "                    plt.colorbar()\n",
    "                    plt.title(character+\" \"+CHARAC[attri])\n",
    "                    plt.show()    \n",
    "        if terrain_option:\n",
    "            terrains = self.global_map['terrain']\n",
    "            for ter_attri in ter_attris:\n",
    "                plt.figure(i)\n",
    "                i+=1     \n",
    "                \n",
    "                plt.imshow(terrains[:,:,ter_attri],cmap=plt.cm.cool)\n",
    "                plt.colorbar()\n",
    "                plt.title(\"terrain \"+TERRAIN[ter_attri])\n",
    "                    \n",
    "                    \n",
    "    def act(self, actions):\n",
    "        # actions: 8 * 8 [x, y, x_w, y_w, damage_w, food_w, health_w, frozen_w]\n",
    "        # self.attack_objs: n_bojs * 7 [id, x, y, damage, food, health, frozen]\n",
    "        # id, x, y, level, damage, food, water, health, frozen\n",
    "        \n",
    "        actions = actions.reshape((8, 8))\n",
    "        moves = np.zeros(actions.shape[0])\n",
    "        scores = np.zeros((actions.shape[0], self.attack_objs.shape[0], 2))\n",
    "        dists = {}\n",
    "        idx = [0, 1, 2, 4, 5, 6, 7, 8]\n",
    "        self.attack_objs = self.attack_objs[:,idx]\n",
    "        id_level = {}\n",
    "        for obj in self.attack_objs:\n",
    "            id_level[obj[0]] = obj[3]\n",
    "        for i, a in enumerate(actions):\n",
    "            if np.abs(a[0]) > np.abs(a[1]) and a[0] > 0:\n",
    "                moves[i] = 3\n",
    "            elif np.abs(a[0]) > np.abs(a[1]) and a[0] < 0:\n",
    "                moves[i] = 4\n",
    "            elif np.abs(a[0]) < np.abs(a[1]) and a[1] > 0:\n",
    "                moves[i] = 1\n",
    "            elif np.abs(a[0]) < np.abs(a[1]) and a[1] < 0:\n",
    "                moves[i] = 2\n",
    "            \n",
    "            scores[i][:,1] = np.sum(a[2:] * self.attack_objs[:,1:], 1)\n",
    "            scores[i][:,0] = self.attack_objs[:,0]\n",
    "            scores = scores[np.argsort(scores[:,1])[::-1]] # sort\n",
    "            dists[i] = {}\n",
    "            dist = np.sqrt(np.sum(np.square(self.attack_objs[:,1:3] - a[:2]), 1))\n",
    "            for obj in self.attack_objs:\n",
    "                dists[i][obj[0]] = dist\n",
    "        \n",
    "        central_dist = np.linalg.norm(actions[:,:2], axis=1)\n",
    "        moves = np.where(central_dist < 0.1, 0, moves)\n",
    "        \n",
    "        actions = {}\n",
    "        for i in range(actions.shape[0]):\n",
    "            a = {action.Attack:{\n",
    "                    action.Style: None,\n",
    "                    action.Target: None\n",
    "                },\n",
    "                 action.Move: {\n",
    "                    action.Direction: None\n",
    "                }\n",
    "                }\n",
    "            if moves[i]:\n",
    "                a[action.Move][action.Direction] = moves[i]\n",
    "\n",
    "            for score in scores[i]:\n",
    "                dist = dists[i][score[0]]\n",
    "                if dist > 4:\n",
    "                    continue\n",
    "                elif dist <= 1:\n",
    "                    a[action.Attack][action.Style] = 0\n",
    "                elif dist <= 3:\n",
    "                    a[action.Attack][action.Style] = 1\n",
    "                elif dist <= 4:\n",
    "                    a[action.Attack][action.Style] = 2\n",
    "                a[action.Attack][action.Target] = score[0]\n",
    "                self.last_action_informations[i][0] = score[0]\n",
    "                self.last_action_informations[i][1] = id_level[score[0]]\n",
    "                break\n",
    "            \n",
    "            actions[i] = a\n",
    "        \n",
    "        return actions\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18beb501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ijcai2022nmmo import CompetitionConfig, scripted, TeamBasedEnv\n",
    "import nmmo\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "Config = CompetitionConfig()\n",
    "env = TeamBasedEnv(Config)\n",
    "myteam = MyAwesomeTeam('myteam',Config)\n",
    "myteam.reset()\n",
    "obs = env.reset()\n",
    "obs_team = obs[0]\n",
    "new_obs = myteam.update_map(obs_team)\n",
    "print(new_obs)\n",
    "# print(new_obs[0].shape)\n",
    "# print(new_obs[1].shape)\n",
    "\n",
    "myteam.show_map([\"agents\",\"oppos\",\"npcs\"],[0,1],[0,1,2,3,4,5,6],agent_index=0,terrain_option=True,ter_attris=[0,1,2,3,4,5,6,7])\n",
    "\n",
    "print( len(myteam.attack_objs) )  # attack_objs -> list[ np.ndarray(float32) ] 8个agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56342a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "myteam.global_map[\"terrain\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ebac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "observe = [spaces.Box(low=-1.0,high=1.0,shape=(20,20),dtype=np.float32)]*3\n",
    "print(tuple(observe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d29d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray \n",
    "import ray.rllib.agents.ppo as ppo\n",
    "from ray.tune.logger import pretty_print\n",
    "import tqdm\n",
    "import json5\n",
    "import ray.tune as tune \n",
    "import gym\n",
    "import gym.spaces as spaces\n",
    "import numpy as np\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "######### load config \n",
    "with open(\"config.json\") as json_file:\n",
    "    all_config = json5.load(json_file)\n",
    "    \n",
    "# all_config[\"lr\"] = tune.grid_search([0.001,0.005])\n",
    "# all_config[\"env\"] = \"MyTrainEnv\"\n",
    "    \n",
    "print(pretty_print(all_config[\"algo_config\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e379cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### register env    \n",
    "def trainenv_creator(env_config):\n",
    "    return MyTrainEnv(env_config)\n",
    "\n",
    "register_env(\"MyTrainEnv\",trainenv_creator)\n",
    "# trainer = ppo.PPOTrainer(env=\"MyTrainEnv\",config=all_config[\"algo_config\"] )# config to pass to env class\n",
    "\n",
    "all_config[\"env\"] = \"MyTrainEnv\"\n",
    "all_config[\"lr\"] = tune.grid_search([0.001,0.0005])\n",
    "\n",
    "tune.run('PPO',\n",
    "         config=all_config[\"algo_config\"],\n",
    "         stop={\"timesteps_total\":40000}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ee2b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "exp = [0]\n",
    "for i in range(2,99+1):\n",
    "    increment = np.floor(i-1 + 300*(2**((i-1)/7.0)))/4.0\n",
    "    exp += [exp[-1] + increment]\n",
    "exp = np.floor(np.array(exp))\n",
    "plt.plot(exp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0265c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nmmo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5e089f20ff9a6989e90675a752ef78a0ebed36f0cfd6ab8ec203886994b2675b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
